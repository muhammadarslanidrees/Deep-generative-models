{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "import GANS\n",
    "import xgboost as xgb\n",
    "from GANS import *\n",
    "importlib.reload(GANS)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataWrangling(fname, dropCols, catFea, label):\n",
    "\n",
    "\n",
    "    if catFea:\n",
    "        dfCat = pd.read_csv(fname, usecols = catFea)\n",
    "\n",
    "        for cat in catFea:\n",
    "            dfCat[cat] = dfCat[cat].apply(str)\n",
    "\n",
    "        dfCat = pd.get_dummies(dfCat, prefix=catFea, dtype = float)\n",
    "        df = pd.read_csv(fname)\n",
    "\n",
    "        for cat in dfCat.columns:\n",
    "            print(cat)\n",
    "            df.loc[:, cat] = dfCat[cat]\n",
    "            del dfCat[cat]\n",
    "\n",
    "        del dfCat\n",
    "        df = df.drop(catFea, axis=1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        df = pd.read_csv(fname)\n",
    "\n",
    "        catCols = df.select_dtypes(include=[\n",
    "            'object']).columns.tolist()\n",
    "\n",
    "        df = df.drop(dropCols, axis=1)\n",
    "\n",
    "        for cat in catFea:\n",
    "            df[cat] = df[cat].apply(str)\n",
    "            \n",
    "        if catCols:\n",
    "\n",
    "            df = pd.get_dummies(df, prefix=(\n",
    "                catCols + catFea), dtype = float)\n",
    "\n",
    "    indepCols = [col for col in df.columns if col != label]\n",
    "    return list(indepCols), df.copy()\n",
    "\n",
    "def meanNormalization(df, indepCols, mndenom):\n",
    "\n",
    "    if mndenom == 'range':\n",
    "        denom = (df[indepCols].max() - df[indepCols].min())\n",
    "    elif mndenom == 'std':\n",
    "        denom = df[indepCols].std()\n",
    "\n",
    "    df[indepCols] = (df[indepCols] - df[indepCols].mean()) / denom\n",
    "    return df.copy()\n",
    "\n",
    "def dataIngestPreProp(folderName, label, catFea, dropCols, mntype, mndenom):\n",
    "\n",
    "    print('Ingesting data within memory, and performing pre-processing')\n",
    "\n",
    "    DATA_DIR = '%s/data/%s/'%(os.getcwd(), folderName)\n",
    "    PROCESSED_DATA_DIR = '%sprocessed/'%DATA_DIR\n",
    "\n",
    "    if not os.path.isdir(PROCESSED_DATA_DIR):\n",
    "        os.makedirs(PROCESSED_DATA_DIR)\n",
    "\n",
    "    outFname = '%s%s (%s %s)'%(PROCESSED_DATA_DIR, folderName, mntype, mndenom)\n",
    "\n",
    "    if os.path.isfile('%s train.csv'%outFname):\n",
    "        train = pd.read_csv('%s train.csv'%outFname)\n",
    "\n",
    "    else:\n",
    "\n",
    "        fname = glob.glob('%s/*.csv'%DATA_DIR)[0]\n",
    "        indepCols, df = dataWrangling(fname, dropCols, catFea, label)\n",
    "\n",
    "        if mntype == 'all':\n",
    "        \n",
    "            df = meanNormalization(df.copy(), list(indepCols), mndenom)\n",
    "            \n",
    "            train, test = train_test_split(df, test_size=0.3, random_state=0,\n",
    "                stratify = df[label])\n",
    "\n",
    "        elif mntype == 'split':\n",
    "\n",
    "            print('split')\n",
    "            train, test = train_test_split(df, test_size=0.2, random_state=0,\n",
    "                stratify = df[label])           \n",
    "\n",
    "            train = meanNormalization(train.copy(), list(indepCols), mndenom)\n",
    "            test = meanNormalization(test.copy(), list(indepCols), mndenom)\n",
    "\n",
    "        train.to_csv('%s train.csv'%outFname, index = False)\n",
    "        test.to_csv('%s test.csv'%outFname, index = False)\n",
    "        del test\n",
    "\n",
    "    return outFname, train.copy()\n",
    "\n",
    "def trainGANS(train, label, rand_dim, base_n_count, epochs,\n",
    "    batch_size, learning_rate, d_pre_train_steps, model,\n",
    "    folderName):\n",
    "\n",
    "    print('Training GANS')\n",
    "\n",
    "    label_cols = [label]\n",
    "    data_cols = [col for col in train.columns if col != label_cols[0]]\n",
    "    MODEL_CACHE_DIR = '%s/cache/%s/'%(os.getcwd(), folderName.split('/')[0])\n",
    "\n",
    "    modelPath = '%s%s_generator_model_weights_step_%d.h5'%(\n",
    "        MODEL_CACHE_DIR, folderName.split('/')[1], (epochs - 1))\n",
    "\n",
    "    if not os.path.exists(modelPath):\n",
    "\n",
    "        k_d = 1  # number of critic network updates per adversarial training step\n",
    "        k_g = 1  # number of generator network updates per adversarial training step\n",
    "\n",
    "        if not os.path.isdir(MODEL_CACHE_DIR):\n",
    "            os.makedirs(MODEL_CACHE_DIR)\n",
    "        \n",
    "        train_no_label = train[data_cols]\n",
    "\n",
    "        arguments = [rand_dim, epochs, batch_size,  k_d, k_g, d_pre_train_steps,\n",
    "            1000, learning_rate, base_n_count, MODEL_CACHE_DIR, None, None, None, True, folderName]\n",
    "\n",
    "        if model == 'gan':\n",
    "            adversarial_training_GAN(arguments, train_no_label, data_cols)\n",
    "            \n",
    "        elif model == 'cgan':\n",
    "            adversarial_training_GAN(arguments, train, data_cols=data_cols,\n",
    "                label_cols=label_cols)\n",
    "\n",
    "        elif model == 'wgan':\n",
    "            adversarial_training_WGAN(arguments, train_no_label, data_cols=data_cols)\n",
    "\n",
    "        elif model == 'wcgan':\n",
    "            adversarial_training_WGAN(arguments, train, data_cols=data_cols,\n",
    "                label_cols=label_cols)\n",
    "\n",
    "    return data_cols, label_cols, modelPath\n",
    "\n",
    "def findSynthesizedData(rand_dim, data_cols, label_cols,\n",
    "    base_n_count, model_name, train, outFname, modelPath):\n",
    "\n",
    "    print('Producing generated examples for the minority class')\n",
    "    balancedFname = '%s %s-balanced.csv'%(outFname, model_name)\n",
    "\n",
    "    if os.path.isfile(balancedFname):\n",
    "        return pd.read_csv(balancedFname).copy()\n",
    "\n",
    "    else:\n",
    "\n",
    "        label_counts = train[label_cols[0]].value_counts()\n",
    "        gen_samples = label_counts[0] - label_counts[1]\n",
    "\n",
    "        data_dim = len(data_cols)\n",
    "        label_dim = len(label_cols)\n",
    "\n",
    "        generator_model, discriminator_model, combined_model = define_models_CGAN(\n",
    "            rand_dim, data_dim, label_dim, base_n_count)\n",
    "        \n",
    "        generator_model.load_weights(modelPath)\n",
    "        z = np.random.normal(size=(gen_samples, rand_dim))\n",
    "        labels = np.array([[1.]] * gen_samples)\n",
    "        g_z = generator_model.predict([z, labels])\n",
    "        dfTrueGen = pd.DataFrame(g_z, columns = (data_cols + label_cols))\n",
    "        trainBalanced = train.append(dfTrueGen)\n",
    "        trainBalanced.to_csv(balancedFname, index = False)\n",
    "        \n",
    "        return trainBalanced.copy()\n",
    "\n",
    "def recall(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'recall',  recall_score(labels, np.round(preds))\n",
    "\n",
    "def precision(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'precision',  precision_score(labels, np.round(preds))\n",
    "\n",
    "def roc_auc(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'roc_auc',  roc_auc_score(labels, preds)\n",
    "\n",
    "def BaseMetrics(y_pred,y_true):\n",
    "\n",
    "    TP = np.sum( (y_pred == 1) & (y_true == 1) )\n",
    "    TN = np.sum( (y_pred == 0) & (y_true == 0) )\n",
    "    FP = np.sum( (y_pred == 1) & (y_true == 0) )\n",
    "    FN = np.sum( (y_pred == 0) & (y_true == 1) )\n",
    "    \n",
    "    return TP, TN, FP, FN\n",
    "\n",
    "def applyModel(train_df, folderName, mntype, mndenom, model_name, outFname, y_col):\n",
    "\n",
    "    if len(train_df) == 0:\n",
    "        model_name = 'N/A'\n",
    "        train_df = pd.read_csv('%s train.csv'%outFname)\n",
    "\n",
    "    title = 'GAN ALGORITHM: %s | MEAN NORM TYPE: %s | MEAN NORM DENOM: %s'%(\n",
    "        model_name.title(), mntype.title(), mndenom.title())\n",
    "\n",
    "    print('Applying XGBoost to perform performance audit of %s'%title)\n",
    "    test_df = pd.read_csv('%s test.csv'%outFname)\n",
    "\n",
    "    X_col = test_df.columns.tolist()\n",
    "    X_col.remove(y_col)\n",
    "    # X_col = test_df.columns[:-1]\n",
    "    # y_col = test_df.columns[-1]\n",
    "    dtrain = xgb.DMatrix(train_df[X_col], train_df[y_col], feature_names=X_col)\n",
    "    dtest = xgb.DMatrix(test_df[X_col], test_df[y_col], feature_names=X_col)\n",
    "\n",
    "    xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'random_state': 0,\n",
    "        'eval_metric': 'auc'\n",
    "    }\n",
    "\n",
    "    xgb_test = xgb.train(xgb_params, dtrain, num_boost_round=100, \n",
    "                         verbose_eval=False,\n",
    "                         early_stopping_rounds=20, \n",
    "                         evals=[(dtrain,'train'),(dtest,'test')],\n",
    "                         evals_result = {},              \n",
    "                         feval = recall, maximize=True\n",
    "                        )\n",
    "\n",
    "    y_pred = xgb_test.predict(dtest, ntree_limit=xgb_test.best_iteration+1)\n",
    "#     y_true = test_df['Class'].values\n",
    "    y_true = test_df[y_col].values\n",
    "\n",
    "    TP, TN, FP, FN = BaseMetrics(np.round(y_pred),y_true)\n",
    "    ACC = ( TP + TN ) / ( TP + TN + FP + FN )\n",
    "\n",
    "    with open(\"%s performance.txt\"%folderName, \"a\") as myfile: \n",
    "\n",
    "        myfile.write('\\n%s'%title)\n",
    "        myfile.write(\"\\n\\nnbest iteration: %d\"%xgb_test.best_iteration)\n",
    "        myfile.write(\"\\nrecall: %f\"%recall(y_pred, dtest)[1])\n",
    "        myfile.write(\"\\nprecision: %f\"%precision(y_pred, dtest)[1])\n",
    "        myfile.write(\"\\nroc auc: %f\"%roc_auc(y_pred, dtest)[1])\n",
    "        myfile.write(\"\\nTP: %d, TN: %d, FP: %d, FN: %d\"%(TP, TN, FP, FN))\n",
    "        myfile.write(\"\\naccuracy: %f\\n\\n\\n\\n\"%ACC)\n",
    "\n",
    "def main(folderName = 'mortgage', label = 'TARGET', catFea = ['NAME_CONTRACT_TYPE',\n",
    "    'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_TYPE_SUITE',\n",
    "    'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
    "    'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START',\n",
    "    'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE',\n",
    "    'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE'],\n",
    "    dropCols = [], rand_dim = 32, base_n_count = 128,\n",
    "    epochs = 50001, batch_size = 64, learning_rate = 0.0001,\n",
    "    d_pre_train_steps = 100, model = 'wcgan', mntype = 'split',\n",
    "    mndenom = 'range', skip =False):\n",
    "\n",
    "    outFname, train = dataIngestPreProp(\n",
    "        folderName, label, catFea, dropCols, mntype, mndenom)\n",
    "    \n",
    "    if skip:\n",
    "        trainBalanced = []\n",
    "    else:\n",
    "        data_cols, label_cols, modelPath = trainGANS(train[train[label] == 1].copy(\n",
    "            ), label, rand_dim, base_n_count, epochs, batch_size,\n",
    "            learning_rate, d_pre_train_steps, model, '%s/%s-%s-%s/'%(\n",
    "                folderName, model, mntype, mndenom))\n",
    "\n",
    "        trainBalanced = findSynthesizedData(rand_dim, data_cols, label_cols,\n",
    "            base_n_count, model.upper(), train.copy(), outFname, modelPath)\n",
    "\n",
    "    applyModel(trainBalanced.copy(), folderName, mntype, mndenom, model, outFname, label)\n",
    "\n",
    "def iterateModels():\n",
    "\n",
    "    for model in ['wcgan']:\n",
    "        for mntype in ['all', 'split']:\n",
    "            for mndenom in ['range', 'std']:\n",
    "                main(mntype = mntype, mndenom = mndenom, model = model, skip = True)\n",
    "                main(mntype = mntype, mndenom = mndenom, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script import *\n",
    "# dataIngestPreProp()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
